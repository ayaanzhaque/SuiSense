{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions\n",
    "This is our code for taking in a user's text and making a prediction based on that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ayaanhaque/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/ayaanhaque/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# set configurations\n",
    "pd.set_option('display.max_columns', 100)\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "# model imports\n",
    "from sklearn.feature_extraction.text import CountVectorizer, HashingVectorizer, TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, roc_auc_score\n",
    "import pickle\n",
    "import joblib\n",
    "\n",
    "# NLP Imports\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "\n",
    "from warnings import simplefilter\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "from PIL import Image\n",
    "import wordninja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing_text(series_to_process):\n",
    "    new_list = []\n",
    "    tokenizer = RegexpTokenizer(r'(\\w+)')\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    for i in range(len(series_to_process)):\n",
    "        # tokenized item in a new list\n",
    "        dirty_string = (series_to_process)[i].lower()\n",
    "        words_only = tokenizer.tokenize(dirty_string) # words_only is a list of only the words, no punctuation\n",
    "        #Lemmatize the words_only\n",
    "        words_only_lem = [lemmatizer.lemmatize(i) for i in words_only]\n",
    "        # removing stop words\n",
    "        words_without_stop = [i for i in words_only_lem if i not in stopwords.words(\"english\")]\n",
    "        # return seperated words\n",
    "        long_string_clean = \" \".join(word for word in words_without_stop)\n",
    "        new_list.append(long_string_clean)\n",
    "        return new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "0    Hello. Depression has always been a secondary ...\n",
      "dtype: object\n",
      "0    hello depression ha always secondary problem m...\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "text = \"Hello. Depression has always been a secondary problem for me, with my main antagonist being severe Harm OCD. But since my relationship ended 8 months ago, I've been stuck in this horrific cycle of absolutely loathing myself, feeling heavy/tired and totally unmotivated to do anything. It's like I'm living in a 2 dimensional world. Nothing in life jumps out and catches my attention like it used to. I used to be quite creative but it's just taken a nose dive. Any work I do is utterly awful and I'm amazed I'm not been kicked off projects (I work freelance). I wake up and I just want to be dead, quite honestly. In fact in the last few weeks I've even found getting out of bed to be a monumental struggle in itself, where I'm almost in tears from the weight of everything.\"\n",
    "# text = \"why does it hurt so much? Why can’t I be happy without it? There’s this empty void in my heart that gets bigger everyday. I’m just waiting until it eats me up, since I’ll never have 2 sided love.\"\n",
    "text2 = \"I don't know what I'm gonna do if I don't perform the way I should. But I certainly know that I will die if he does. In case everything goes wrong, I'll leave. There's no other way. The day of my death is nearing. It's just 3 months away. Love you all. Have a good day.\"\n",
    "text_array = pd.Series(text)\n",
    "print(type(text_array))\n",
    "print(text_array)\n",
    "processed_text = processing_text(text_array)\n",
    "\n",
    "processed_array = pd.Series(processed_text)\n",
    "\n",
    "print(processed_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "model = joblib.load(\"model2.h5\")\n",
    "\n",
    "tvec_optimised = TfidfVectorizer(max_features=70, ngram_range=(1, 3),stop_words = 'english')\n",
    "processed_text_tvec = tvec_optimised.fit_transform(processed_array).todense()\n",
    "\n",
    "prediction = model.predict(processed_text_tvec)\n",
    "print(prediction[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
