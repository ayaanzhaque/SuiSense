{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Progression Model\n",
    "This is our model for determining the progression of someone's suicidal tendencies and depression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Victoria's Diary\n",
    "This is a dataset that we will use to train our progression.\n",
    "\n",
    "Victoria's family made the contents of her diary available to Jesse Bering, a research psychologist at the University of Otago in New Zealand. We scraped exerpts of the diary from Bering's published findings in his book Suicidal: Why We Kill Ourselves.\n",
    "\n",
    "Applying our model to Victoria's writings allows us to see if our model -- trained on data from online communities -- would generalise well to an unseen test set. In this case, an individual's words.\n",
    "\n",
    "Using social psychologist Roy Baumeister's theory, Bering mapped different parts of Victoria's diary to six different progressive stages from \"falling short of expectations\"(stage one) to \"high self-awareness\"(stage three) to the final stage of \"disinhibition\". We've matched Bering's findings to each diary exerpt in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option('display.max_columns', 100)\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, HashingVectorizer, TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, roc_auc_score\n",
    "\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data = pd.read_csv('../data/data_for_model.csv', keep_default_na=False)\n",
    "vics_diary = pd.read_csv('../data/vics_diary.csv', keep_default_na=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1897 entries, 0 to 1896\n",
      "Data columns (total 12 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   title            1897 non-null   object\n",
      " 1   selftext         1897 non-null   object\n",
      " 2   author           1897 non-null   object\n",
      " 3   num_comments     1897 non-null   int64 \n",
      " 4   is_suicide       1897 non-null   int64 \n",
      " 5   url              1897 non-null   object\n",
      " 6   selftext_clean   1897 non-null   object\n",
      " 7   title_clean      1897 non-null   object\n",
      " 8   author_clean     1897 non-null   object\n",
      " 9   selftext_length  1897 non-null   int64 \n",
      " 10  title_length     1897 non-null   int64 \n",
      " 11  megatext_clean   1897 non-null   object\n",
      "dtypes: int64(4), object(8)\n",
      "memory usage: 178.0+ KB\n"
     ]
    }
   ],
   "source": [
    "model_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 62 entries, 0 to 61\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   vic_detail   62 non-null     object\n",
      " 1   journ_entry  62 non-null     object\n",
      " 2   stage        62 non-null     int64 \n",
      " 3   notes        62 non-null     object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 2.1+ KB\n"
     ]
    }
   ],
   "source": [
    "vics_diary.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62, 4)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vics_diary.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vic_detail</th>\n",
       "      <th>journ_entry</th>\n",
       "      <th>stage</th>\n",
       "      <th>notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Final Group Text to her friends</td>\n",
       "      <td>\"Love you all, sorry guys.\"</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Letter meant for Grace</td>\n",
       "      <td>\"I just\\nwant to say that it has been an hones...</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Letter meant for Grace</td>\n",
       "      <td>\"If you ever feel\\rsad or lonely/' Vic wrote i...</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>no timestamp</td>\n",
       "      <td>\"I don 't want other kids to feel like freaks ...</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>poem</td>\n",
       "      <td>She laid her head on the pillow beside me,\\nFl...</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        vic_detail  \\\n",
       "0  Final Group Text to her friends   \n",
       "1           Letter meant for Grace   \n",
       "2           Letter meant for Grace   \n",
       "3                     no timestamp   \n",
       "4                             poem   \n",
       "\n",
       "                                         journ_entry  stage notes  \n",
       "0                        \"Love you all, sorry guys.\"      0        \n",
       "1  \"I just\\nwant to say that it has been an hones...      0        \n",
       "2  \"If you ever feel\\rsad or lonely/' Vic wrote i...      0        \n",
       "3  \"I don 't want other kids to feel like freaks ...      0        \n",
       "4  She laid her head on the pillow beside me,\\nFl...      0        "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vics_diary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing_text(series_to_process):\n",
    "    new_list = []\n",
    "    tokenizer = RegexpTokenizer(r'(\\w+)')\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    for i in range(len(series_to_process)):\n",
    "        # tokenize items\n",
    "        dirty_string = (series_to_process)[i].lower()\n",
    "        words_only = tokenizer.tokenize(dirty_string)\n",
    "        # lemmatize\n",
    "        words_only_lem = [lemmatizer.lemmatize(i) for i in words_only]\n",
    "        # removing stop words from lemmatization\n",
    "        words_without_stop = [i for i in words_only_lem if i not in stopwords.words(\"english\")]\n",
    "        # return seperated words\n",
    "        long_string_clean = \" \".join(word for word in words_without_stop)\n",
    "        new_list.append(long_string_clean)\n",
    "    return new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vics_diary[\"journ_entry_clean\"] = processing_text(vics_diary[\"journ_entry\"])\n",
    "pd.set_option(\"display.max_colwidth\", 100)\n",
    "vics_diary.head(8)\n",
    "print(vics_diary[\"journ_entry\"][10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vics_diary.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Data\n",
    "def TF_IDF_most_used_words(category_string, data_series, palette, image_mask):\n",
    "    # find most common words\n",
    "    tvec_optimised = TfidfVectorizer(max_df= 0.5, max_features=70, min_df=2, ngram_range=(1, 3),stop_words = 'english')\n",
    "    tvec_optimised.fit(data_series)\n",
    "    # create dataframe\n",
    "    created_df = pd.DataFrame(tvec_optimised.transform(data_series).todense(),\n",
    "                              columns=tvec_optimised.get_feature_names())\n",
    "    total_words = created_df.sum(axis=0)\n",
    "    \n",
    "    # create dataframe of top 20 words\n",
    "    top_20_words = total_words.sort_values(ascending = False).head(20)\n",
    "    top_20_words_df = pd.DataFrame(top_20_words, columns = [\"count\"])\n",
    "\n",
    "    # plotting\n",
    "    sns.set_style(\"white\")\n",
    "    plt.figure(figsize = (12, 5), dpi=300)\n",
    "    ax = sns.barplot(y= top_20_words_df.index, x=\"count\", data=top_20_words_df, palette = palette)\n",
    "    plt.xlabel(\"Count\", fontsize=9)\n",
    "    plt.ylabel('Common Words in {}'.format(category_string), fontsize=9)\n",
    "    plt.yticks(rotation=-5)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TF_IDF_most_used_words(\"Words indicative of suicide in Victoria's Diary\", vics_diary[\"journ_entry_clean\"], \"vlag_r\", image_mask=\"../assets/a_victoria_mask_2.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using model for testing\n",
    "\n",
    "X_train = model_data[\"megatext_clean\"]\n",
    "y_train = model_data['is_suicide']\n",
    "\n",
    "#Â using the diary as a test set\n",
    "X_test = vics_diary[\"journ_entry_clean\"]\n",
    "\n",
    "# fitting vectors\n",
    "tvec_optimised = TfidfVectorizer(max_df= 0.5, max_features=70, min_df=2, ngram_range=(1, 3),stop_words = 'english')\n",
    "X_train_tvec = tvec_optimised.fit_transform(X_train).todense()\n",
    "X_test_tvec = tvec_optimised.transform(X_test).todense()\n",
    "\n",
    "# fitting MNB Model\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train_tvec, y_train)\n",
    "\n",
    "# getting predictions\n",
    "predictions = nb.predict(X_test_tvec)\n",
    "\n",
    "# adding predictions to dataframe\n",
    "vics_diary[\"predicted_suicide\"] = pd.DataFrame(predictions)\n",
    "pd.set_option(\"display.max_colwidth\", 300)\n",
    "pd.set_option(\"display.max_rows\", 101)\n",
    "vics_diary[[\"journ_entry\", \"vic_detail\", \"predicted_suicide\" ]].sort_values(\"vic_detail\", ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are six stages that can be determined in Victoria's diary.\n",
    "\n",
    "Stage 1: Falling Short of Expectations\n",
    "\n",
    "Stage 2: Attributions to Self\n",
    "\n",
    "Stage 3: High Self-Awareness\n",
    "\n",
    "Stage 4: Negative Affect\n",
    "\n",
    "Stage 5: Cognitive Deconstruction\n",
    "\n",
    "Stage 6: Disinhibition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average predictions\n",
    "vics_diary[\"predicted_suicide\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking entries per stage\n",
    "vics_diary[\"vic_detail\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting predictions per stage\n",
    "vic_plot_df = pd.DataFrame(vics_diary.groupby(\"vic_detail\")[\"predicted_suicide\"].value_counts())\n",
    "vic_plot_df.columns = [\"counts\"]\n",
    "vic_plot_df = vic_plot_df.reset_index()\n",
    "vic_plot_df = vic_plot_df.iloc[[2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,0,1],:]\n",
    "vic_plot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentage of Entries categorized as Suicidal \n",
    "pure_entries_total = vic_plot_df[vic_plot_df[\"vic_detail\"].str.contains(\"Stage\")][\"counts\"].sum()\n",
    "pure_entries_predicted_suicide = vic_plot_df[vic_plot_df[\"vic_detail\"].str.contains(\"Stage\")][vic_plot_df[vic_plot_df[\"vic_detail\"].str.contains(\"Stage\")][\"predicted_suicide\"]==1][\"counts\"].sum()\n",
    "\n",
    "pure_entries_predicted_suicide/pure_entries_total\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only about 70 percent of her entries were classified as suicidal, proving how cryptic these messages can be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREATING A BARPLOT TO VISUALISE HOW THE MODEL CLASSIFIED VICTORIA'S ENTRIES\n",
    "sns.set_style(\"white\")\n",
    "colors = [\"dark slate blue\", \"dark red\"]  \n",
    "myPalette = sns.xkcd_palette(colors)\n",
    "plt.figure(figsize = (15, 10), dpi=300)\n",
    "plt.title(\"Classification of entries in Victoria's Diary\\n\", fontsize=14)\n",
    "ax = sns.barplot(y='vic_detail', x='counts', data=vic_plot_df, hue='predicted_suicide', palette=myPalette, errwidth=0.01);\n",
    "plt.ylabel(\"category of entries\");"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
