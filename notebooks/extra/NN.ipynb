{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import array\n",
    "from numpy import array\n",
    "from numpy import asarray\n",
    "from numpy import zeros\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# set configurations\n",
    "pd.set_option('display.max_columns', 100)\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "# keras imports\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Activation, Dropout, Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import GlobalMaxPooling1D, SpatialDropout1D, LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# model imports\n",
    "from sklearn.feature_extraction.text import CountVectorizer, HashingVectorizer, TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, roc_auc_score\n",
    "import pickle\n",
    "import joblib\n",
    "\n",
    "from warnings import simplefilter\n",
    "simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data = pd.read_csv('../data/scheme1.csv', keep_default_na=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>author</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>is_suicide</th>\n",
       "      <th>url</th>\n",
       "      <th>selftext_clean</th>\n",
       "      <th>title_clean</th>\n",
       "      <th>author_clean</th>\n",
       "      <th>selftext_length</th>\n",
       "      <th>title_length</th>\n",
       "      <th>megatext_clean</th>\n",
       "      <th>Clustered Labels</th>\n",
       "      <th>New Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Our most-broken and least-understood rules is ...</td>\n",
       "      <td>We understand that most people who reply immed...</td>\n",
       "      <td>SQLwitch</td>\n",
       "      <td>133</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.reddit.com/r/depression/comments/d...</td>\n",
       "      <td>understand people reply immediately op invitat...</td>\n",
       "      <td>broken least understood rule helper may invite...</td>\n",
       "      <td>sql witch</td>\n",
       "      <td>4792</td>\n",
       "      <td>144</td>\n",
       "      <td>sql witch understand people reply immediately ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Regular Check-In Post</td>\n",
       "      <td>Welcome to /r/depression's check-in post - a p...</td>\n",
       "      <td>circinia</td>\n",
       "      <td>1644</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.reddit.com/r/depression/comments/e...</td>\n",
       "      <td>welcome r depression check post place take mom...</td>\n",
       "      <td>regular check post</td>\n",
       "      <td>c irc</td>\n",
       "      <td>650</td>\n",
       "      <td>21</td>\n",
       "      <td>c irc welcome r depression check post place ta...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>I hate it so much when you try and express you...</td>\n",
       "      <td>I've been feeling really depressed and lonely ...</td>\n",
       "      <td>TheNewKiller69</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.reddit.com/r/depression/comments/f...</td>\n",
       "      <td>feeling really depressed lonely lately job ful...</td>\n",
       "      <td>hate much try express feeling parent turn arou...</td>\n",
       "      <td>new killer 69</td>\n",
       "      <td>1866</td>\n",
       "      <td>137</td>\n",
       "      <td>new killer 69 feeling really depressed lonely ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1  \\\n",
       "0           0             0   \n",
       "1           1             1   \n",
       "2           2             2   \n",
       "\n",
       "                                               title  \\\n",
       "0  Our most-broken and least-understood rules is ...   \n",
       "1                              Regular Check-In Post   \n",
       "2  I hate it so much when you try and express you...   \n",
       "\n",
       "                                            selftext          author  \\\n",
       "0  We understand that most people who reply immed...        SQLwitch   \n",
       "1  Welcome to /r/depression's check-in post - a p...        circinia   \n",
       "2  I've been feeling really depressed and lonely ...  TheNewKiller69   \n",
       "\n",
       "   num_comments  is_suicide  \\\n",
       "0           133           0   \n",
       "1          1644           0   \n",
       "2             8           0   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://www.reddit.com/r/depression/comments/d...   \n",
       "1  https://www.reddit.com/r/depression/comments/e...   \n",
       "2  https://www.reddit.com/r/depression/comments/f...   \n",
       "\n",
       "                                      selftext_clean  \\\n",
       "0  understand people reply immediately op invitat...   \n",
       "1  welcome r depression check post place take mom...   \n",
       "2  feeling really depressed lonely lately job ful...   \n",
       "\n",
       "                                         title_clean   author_clean  \\\n",
       "0  broken least understood rule helper may invite...      sql witch   \n",
       "1                                 regular check post          c irc   \n",
       "2  hate much try express feeling parent turn arou...  new killer 69   \n",
       "\n",
       "   selftext_length  title_length  \\\n",
       "0             4792           144   \n",
       "1              650            21   \n",
       "2             1866           137   \n",
       "\n",
       "                                      megatext_clean  Clustered Labels  \\\n",
       "0  sql witch understand people reply immediately ...                 1   \n",
       "1  c irc welcome r depression check post place ta...                 1   \n",
       "2  new killer 69 feeling really depressed lonely ...                 0   \n",
       "\n",
       "   New Labels  \n",
       "0           1  \n",
       "1           1  \n",
       "2           0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1897 entries, 0 to 1896\n",
      "Data columns (total 16 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   Unnamed: 0        1897 non-null   int64 \n",
      " 1   Unnamed: 0.1      1897 non-null   int64 \n",
      " 2   title             1897 non-null   object\n",
      " 3   selftext          1897 non-null   object\n",
      " 4   author            1897 non-null   object\n",
      " 5   num_comments      1897 non-null   int64 \n",
      " 6   is_suicide        1897 non-null   int64 \n",
      " 7   url               1897 non-null   object\n",
      " 8   selftext_clean    1897 non-null   object\n",
      " 9   title_clean       1897 non-null   object\n",
      " 10  author_clean      1897 non-null   object\n",
      " 11  selftext_length   1897 non-null   int64 \n",
      " 12  title_length      1897 non-null   int64 \n",
      " 13  megatext_clean    1897 non-null   object\n",
      " 14  Clustered Labels  1897 non-null   int64 \n",
      " 15  New Labels        1897 non-null   int64 \n",
      "dtypes: int64(8), object(8)\n",
      "memory usage: 237.2+ KB\n"
     ]
    }
   ],
   "source": [
    "model_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5166051660516605"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data['is_suicide'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (1517,)\n"
     ]
    }
   ],
   "source": [
    "# getting ready for training\n",
    "\n",
    "X = model_data[\"selftext_clean\"]\n",
    "y = model_data[\"is_suicide\"]\n",
    "# train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print('Shape of data tensor:', X_train.shape)\n",
    "\n",
    "tvec_optimised = TfidfVectorizer(max_df= 0.5, max_features=70, min_df=2, ngram_range=(1, 3),stop_words = 'english')\n",
    "X_train_tvec = tvec_optimised.fit_transform(X_train).todense()\n",
    "X_test_tvec = tvec_optimised.transform(X_test).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_tvec = pad_sequences(X_train_tvec, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "# print('Shape of data tensor:', X_train_tvec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    " \n",
    "model.add(Dense(units=500, activation='relu', input_dim=len(tvec_optimised.get_feature_names())))\n",
    "model.add(Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 500)               35500     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 501       \n",
      "=================================================================\n",
      "Total params: 36,001\n",
      "Trainable params: 36,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1517 samples, validate on 380 samples\n",
      "Epoch 1/10\n",
      "1517/1517 [==============================] - 0s 48us/step - loss: 0.4172 - accuracy: 0.8299 - val_loss: 0.6584 - val_accuracy: 0.6553\n",
      "Epoch 2/10\n",
      "1517/1517 [==============================] - 0s 61us/step - loss: 0.4013 - accuracy: 0.8477 - val_loss: 0.6469 - val_accuracy: 0.6868\n",
      "Epoch 3/10\n",
      "1517/1517 [==============================] - 0s 61us/step - loss: 0.3887 - accuracy: 0.8517 - val_loss: 0.6498 - val_accuracy: 0.6868\n",
      "Epoch 4/10\n",
      "1517/1517 [==============================] - 0s 54us/step - loss: 0.3716 - accuracy: 0.8741 - val_loss: 0.6561 - val_accuracy: 0.6816\n",
      "Epoch 5/10\n",
      "1517/1517 [==============================] - 0s 55us/step - loss: 0.3547 - accuracy: 0.8761 - val_loss: 0.6632 - val_accuracy: 0.6895\n",
      "Epoch 6/10\n",
      "1517/1517 [==============================] - 0s 50us/step - loss: 0.3401 - accuracy: 0.8952 - val_loss: 0.6641 - val_accuracy: 0.6658\n",
      "Epoch 7/10\n",
      "1517/1517 [==============================] - 0s 53us/step - loss: 0.3301 - accuracy: 0.8945 - val_loss: 0.6824 - val_accuracy: 0.6711\n",
      "Epoch 8/10\n",
      "1517/1517 [==============================] - 0s 48us/step - loss: 0.3209 - accuracy: 0.8972 - val_loss: 0.6717 - val_accuracy: 0.6921\n",
      "Epoch 9/10\n",
      "1517/1517 [==============================] - 0s 57us/step - loss: 0.2995 - accuracy: 0.9150 - val_loss: 0.6865 - val_accuracy: 0.6684\n",
      "Epoch 10/10\n",
      "1517/1517 [==============================] - 0s 53us/step - loss: 0.2874 - accuracy: 0.9321 - val_loss: 0.6871 - val_accuracy: 0.6711\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_tvec, y_train, batch_size=32, epochs=10, verbose=1, validation_data=(X_test_tvec, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "380/380 [==============================] - 0s 100us/step\n",
      "Accuracy: 0.6710526347160339\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_test_tvec, y_test, verbose=1)\n",
    "print(\"Accuracy:\", scores[1])  # Accuracy: 0.875"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[15, 40, 57, 64, 19, 55, 41, 58, 40, 64, 64, 47, 23, 67, 64, 63, 49, 61, 61, 36, 55, 21, 47, 23, 56, 64, 64, 44, 0, 47, 36, 12, 32, 21, 15, 9, 65, 9, 30, 6, 2, 14, 57, 36, 60, 53, 18, 9, 30, 65, 54, 36, 40, 2, 30, 47, 12, 30, 55, 51, 21, 47, 23, 56, 58, 58]\n"
     ]
    }
   ],
   "source": [
    "word2idx = {word: idx for idx, word in enumerate(tvec_optimised.get_feature_names())}\n",
    "tokenize = tvec_optimised.build_tokenizer()\n",
    "preprocess = tvec_optimised.build_preprocessor()\n",
    " \n",
    "def to_sequence(tokenizer, preprocessor, index, text):\n",
    "    words = tokenizer(preprocessor(text))\n",
    "    indexes = [index[word] for word in words if word in index]\n",
    "    return indexes\n",
    " \n",
    "print(to_sequence(tokenize, preprocess, word2idx, \"This is an important test!\"))  # [2269, 4453]\n",
    "X_train_sequences = [to_sequence(tokenize, preprocess, word2idx, x) for x in X_train]\n",
    "print(X_train_sequences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAX_SEQ_LENGHT= 488\n",
      "[70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70\n",
      " 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70\n",
      " 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70\n",
      " 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70\n",
      " 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70\n",
      " 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70\n",
      " 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70\n",
      " 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70\n",
      " 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70\n",
      " 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70\n",
      " 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70\n",
      " 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70\n",
      " 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70\n",
      " 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70\n",
      " 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70\n",
      " 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70\n",
      " 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70\n",
      " 70 70 70 70 70 70 70 70 70 70 70 70 70 70 15 40 57 64 19 55 41 58 40 64\n",
      " 64 47 23 67 64 63 49 61 61 36 55 21 47 23 56 64 64 44  0 47 36 12 32 21\n",
      " 15  9 65  9 30  6  2 14 57 36 60 53 18  9 30 65 54 36 40  2 30 47 12 30\n",
      " 55 51 21 47 23 56 58 58]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Compute the max lenght of a text\n",
    "MAX_SEQ_LENGHT = len(max(X_train_sequences, key=len))\n",
    "print(\"MAX_SEQ_LENGHT=\", MAX_SEQ_LENGHT)\n",
    " \n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "N_FEATURES = len(tvec_optimised.get_feature_names())\n",
    "X_train_sequences = pad_sequences(X_train_sequences, maxlen=MAX_SEQ_LENGHT, value=N_FEATURES)\n",
    "print(X_train_sequences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, Embedding\n",
    " \n",
    "model = Sequential()\n",
    "model.add(Embedding(len(tvec_optimised.get_feature_names()) + 1,\n",
    "                    64,  # Embedding size\n",
    "                    input_length=MAX_SEQ_LENGHT))\n",
    "model.add(Conv1D(64, 5, activation='relu'))\n",
    "model.add(MaxPooling1D(5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=64, activation='relu'))\n",
    "model.add(Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_12 (Embedding)     (None, 488, 64)           4544      \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 484, 64)           20544     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 96, 64)            0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 6144)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 64)                393280    \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 418,433\n",
      "Trainable params: 418,433\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_sequences = [to_sequence(tokenize, preprocess, word2idx, x) for x in X_test]\n",
    "X_test_sequences = pad_sequences(X_test_sequences, maxlen=MAX_SEQ_LENGHT, value=N_FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1517 samples, validate on 380 samples\n",
      "Epoch 1/10\n",
      "1517/1517 [==============================] - 3s 2ms/step - loss: 0.1548 - accuracy: 0.9242 - val_loss: 2.0098 - val_accuracy: 0.5658\n",
      "Epoch 2/10\n",
      "1517/1517 [==============================] - 3s 2ms/step - loss: 0.1484 - accuracy: 0.9262 - val_loss: 1.9223 - val_accuracy: 0.5763\n",
      "Epoch 3/10\n",
      "1517/1517 [==============================] - 3s 2ms/step - loss: 0.1463 - accuracy: 0.9255 - val_loss: 1.9247 - val_accuracy: 0.5658\n",
      "Epoch 4/10\n",
      "1517/1517 [==============================] - 3s 2ms/step - loss: 0.1515 - accuracy: 0.9222 - val_loss: 1.9728 - val_accuracy: 0.5632\n",
      "Epoch 5/10\n",
      "1517/1517 [==============================] - 3s 2ms/step - loss: 0.1483 - accuracy: 0.9229 - val_loss: 1.9642 - val_accuracy: 0.5789\n",
      "Epoch 6/10\n",
      "1517/1517 [==============================] - 3s 2ms/step - loss: 0.1474 - accuracy: 0.9249 - val_loss: 1.9712 - val_accuracy: 0.5658\n",
      "Epoch 7/10\n",
      "1517/1517 [==============================] - 3s 2ms/step - loss: 0.1465 - accuracy: 0.9235 - val_loss: 2.0352 - val_accuracy: 0.5553\n",
      "Epoch 8/10\n",
      "1517/1517 [==============================] - 4s 2ms/step - loss: 0.1513 - accuracy: 0.9209 - val_loss: 1.9544 - val_accuracy: 0.5737\n",
      "Epoch 9/10\n",
      "1517/1517 [==============================] - 4s 2ms/step - loss: 0.1451 - accuracy: 0.9249 - val_loss: 1.9512 - val_accuracy: 0.5605\n",
      "Epoch 10/10\n",
      "1517/1517 [==============================] - 4s 2ms/step - loss: 0.1461 - accuracy: 0.9255 - val_loss: 2.0081 - val_accuracy: 0.5763\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_sequences, y_train, batch_size=32, epochs=10, verbose=1, validation_data=(X_test_sequences, y_test))\n",
    "\n",
    "# model.fit(X_train_sequences[:-100], y_train[:-100], \n",
    "#           epochs=100, batch_size=64, verbose=1,\n",
    "#           validation_data=(X_train_sequences[-100:], y_train[-100:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "380/380 [==============================] - 0s 258us/step\n",
      "Accuracy: 0.5763157606124878\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_test_sequences, y_test, verbose=1)\n",
    "print(\"Accuracy:\", scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_13 (Embedding)     (None, 488, 64)           4544      \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 37,633\n",
      "Trainable params: 37,633\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Embedding\n",
    " \n",
    "model = Sequential()\n",
    "model.add(Embedding(len(tvec_optimised.get_feature_names()) + 1,\n",
    "                    64,  # Embedding size\n",
    "                    input_length=MAX_SEQ_LENGHT))\n",
    "model.add(LSTM(64))\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    " \n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1517 samples, validate on 380 samples\n",
      "Epoch 1/10\n",
      "1517/1517 [==============================] - 26s 17ms/step - loss: 0.6785 - accuracy: 0.5570 - val_loss: 0.6790 - val_accuracy: 0.5342\n",
      "Epoch 2/10\n",
      "1517/1517 [==============================] - 25s 16ms/step - loss: 0.6419 - accuracy: 0.6388 - val_loss: 0.6508 - val_accuracy: 0.6368\n",
      "Epoch 3/10\n",
      "1517/1517 [==============================] - 25s 17ms/step - loss: 0.6124 - accuracy: 0.6724 - val_loss: 0.7001 - val_accuracy: 0.6263\n",
      "Epoch 4/10\n",
      "1517/1517 [==============================] - 21s 14ms/step - loss: 0.5938 - accuracy: 0.6856 - val_loss: 0.6500 - val_accuracy: 0.6395\n",
      "Epoch 5/10\n",
      "1517/1517 [==============================] - 27s 18ms/step - loss: 0.5786 - accuracy: 0.7053 - val_loss: 0.6441 - val_accuracy: 0.6711\n",
      "Epoch 6/10\n",
      "1517/1517 [==============================] - 22s 15ms/step - loss: 0.5653 - accuracy: 0.7086 - val_loss: 0.6348 - val_accuracy: 0.6605\n",
      "Epoch 7/10\n",
      "1517/1517 [==============================] - 20s 13ms/step - loss: 0.5540 - accuracy: 0.7271 - val_loss: 0.6264 - val_accuracy: 0.6632\n",
      "Epoch 8/10\n",
      "1517/1517 [==============================] - 20s 13ms/step - loss: 0.5414 - accuracy: 0.7343 - val_loss: 0.6528 - val_accuracy: 0.6605\n",
      "Epoch 9/10\n",
      "1517/1517 [==============================] - 20s 13ms/step - loss: 0.5342 - accuracy: 0.7396 - val_loss: 0.6701 - val_accuracy: 0.6211\n",
      "Epoch 10/10\n",
      "1517/1517 [==============================] - 21s 14ms/step - loss: 0.5243 - accuracy: 0.7488 - val_loss: 0.6822 - val_accuracy: 0.6211\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_sequences, y_train, batch_size=32, epochs=10, verbose=1, validation_data=(X_test_sequences, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'en_core_web_sm'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-99-0da6e161ed90>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0men_core_web_sm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mnlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0men_core_web_sm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'en_core_web_sm'"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import numpy as np\n",
    "\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n",
    "\n",
    "nlp = spacy.load('en_core_web_md')\n",
    " \n",
    "EMBEDDINGS_LEN = len(nlp.vocab['apple'].vector)\n",
    "print(\"EMBEDDINGS_LEN=\", EMBEDDINGS_LEN)  # 300\n",
    " \n",
    "embeddings_index = np.zeros((len(tvec_optimised.get_feature_names()) + 1, EMBEDDINGS_LEN))\n",
    "for word, idx in word2idx.items():\n",
    "    try:\n",
    "        embedding = nlp.vocab[word].vector\n",
    "        embeddings_index[idx] = embedding\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
