{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our Model\n",
    "Here we will be creating different models to classify our data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import array\n",
    "from numpy import array\n",
    "from numpy import asarray\n",
    "from numpy import zeros\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# set configurations\n",
    "pd.set_option('display.max_columns', 100)\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "# keras imports\n",
    "import keras\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Activation, Dropout, Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import GlobalMaxPooling1D\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# model imports\n",
    "from sklearn.feature_extraction.text import CountVectorizer, HashingVectorizer, TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, roc_auc_score\n",
    "import pickle\n",
    "import joblib\n",
    "\n",
    "from warnings import simplefilter\n",
    "simplefilter(action='ignore', category=FutureWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data = pd.read_csv('../data/suicide_vs_nothing.csv', keep_default_na=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>author</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>is_suicide</th>\n",
       "      <th>url</th>\n",
       "      <th>selftext_clean</th>\n",
       "      <th>title_clean</th>\n",
       "      <th>author_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1812</th>\n",
       "      <td>My teenager made me so proud tonight with a si...</td>\n",
       "      <td>I have 4 boys ranging from ages 3 to 14. Tonig...</td>\n",
       "      <td>SedativeCorpse</td>\n",
       "      <td>251</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.reddit.com/r/CasualConversation/co...</td>\n",
       "      <td>4 boy ranging age 3 14 tonight 3 year old wa t...</td>\n",
       "      <td>teenager made proud tonight simple gesture</td>\n",
       "      <td>sedative corpse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1813</th>\n",
       "      <td>After 30 years of being open, my family’s rest...</td>\n",
       "      <td>My family has owned a fine dining italian rest...</td>\n",
       "      <td>retirereddit</td>\n",
       "      <td>769</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.reddit.com/r/CasualConversation/co...</td>\n",
       "      <td>family ha owned fine dining italian restaurant...</td>\n",
       "      <td>30 year open family restaurant closing tonight</td>\n",
       "      <td>retire reddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1814</th>\n",
       "      <td>I’ve been living in Japan for more than a deca...</td>\n",
       "      <td>First of all, I’m not Japanese. I came to Japa...</td>\n",
       "      <td>BeardedGlass</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.reddit.com/r/CasualConversation/co...</td>\n",
       "      <td>first japanese came japan 12 year ago work pro...</td>\n",
       "      <td>living japan decade anyone ha question life co...</td>\n",
       "      <td>bearded glass</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  \\\n",
       "1812  My teenager made me so proud tonight with a si...   \n",
       "1813  After 30 years of being open, my family’s rest...   \n",
       "1814  I’ve been living in Japan for more than a deca...   \n",
       "\n",
       "                                               selftext          author  \\\n",
       "1812  I have 4 boys ranging from ages 3 to 14. Tonig...  SedativeCorpse   \n",
       "1813  My family has owned a fine dining italian rest...    retirereddit   \n",
       "1814  First of all, I’m not Japanese. I came to Japa...    BeardedGlass   \n",
       "\n",
       "      num_comments  is_suicide  \\\n",
       "1812           251           0   \n",
       "1813           769           0   \n",
       "1814            18           0   \n",
       "\n",
       "                                                    url  \\\n",
       "1812  https://www.reddit.com/r/CasualConversation/co...   \n",
       "1813  https://www.reddit.com/r/CasualConversation/co...   \n",
       "1814  https://www.reddit.com/r/CasualConversation/co...   \n",
       "\n",
       "                                         selftext_clean  \\\n",
       "1812  4 boy ranging age 3 14 tonight 3 year old wa t...   \n",
       "1813  family ha owned fine dining italian restaurant...   \n",
       "1814  first japanese came japan 12 year ago work pro...   \n",
       "\n",
       "                                            title_clean     author_clean  \n",
       "1812         teenager made proud tonight simple gesture  sedative corpse  \n",
       "1813     30 year open family restaurant closing tonight    retire reddit  \n",
       "1814  living japan decade anyone ha question life co...    bearded glass  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1815 entries, 0 to 1814\n",
      "Data columns (total 9 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   title           1815 non-null   object\n",
      " 1   selftext        1815 non-null   object\n",
      " 2   author          1815 non-null   object\n",
      " 3   num_comments    1815 non-null   int64 \n",
      " 4   is_suicide      1815 non-null   int64 \n",
      " 5   url             1815 non-null   object\n",
      " 6   selftext_clean  1815 non-null   object\n",
      " 7   title_clean     1815 non-null   object\n",
      " 8   author_clean    1815 non-null   object\n",
      "dtypes: int64(2), object(7)\n",
      "memory usage: 127.7+ KB\n"
     ]
    }
   ],
   "source": [
    "model_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Establishing a baseline accuracy is important for evaluating the model's progression. If every prediction was 1, let's see what our accuracy would be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5399449035812672"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data['is_suicide'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our baseline accuracy is about 51.7%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selection of Features and Attributes\n",
    "Here we are attempting to create a model using CountVectorizer and Naive Bayes Model to determine which columns are the best to score and use for our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our initial model, it will be a binary classifier. Once the user gets their classification, they will go to another model that will give them specific support. \n",
    "\n",
    "Label Encoding: r/SuicideWatch = 1, r/Depression = 0\n",
    "\n",
    "TP: model predicts suicide, and it is correct\n",
    "\n",
    "TN: model predicts depression, and it is correct\n",
    "\n",
    "FP: model predicts suicide, but it is really depression, not good\n",
    "\n",
    "FN: model predicts depression, but they really are suicidal, this is the worst, misses an at risk patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the function\n",
    "columns_list = ['selftext', \"author\", \"title\",'selftext_clean', \"author_clean\", \"title_clean\", \"megatext_clean\"]\n",
    "model = \"CountVec + MultinomialNB\"\n",
    "df_list=[]\n",
    "# multi_modelling(columns_list, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on our results, using the megatext_clean column will be the best option for our model due its good metrics, such as its AUC value. The false negatives are the highest in our confusion matrix, meaning it is good for the model to learn from. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Production Model\n",
    "We will test a few different models by running some perumatations and recording the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After reviewing all the performances, two models stand out. The Hashing Vectorizor and Multinomial Naive Bayes model had much better metrics, along with the TFID Vectorizor and Multinomial Naive Bayes Model. They both have good AUC values and high generalization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF Vectorizor + Multinomial Naive Bayes\n",
    "This model has the best metrics and will work the best for our data. While it isn't the higher AUC, it generalizes better and has higher True Positives. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running our Optimized Model\n",
    "This model is a combination of TF-IDF(\"Term Frequency - Inverse Document\" Frequency) Vectorizer and the Multinomial Naive Bayes. It assigns scores for the top 70 words in our selected feature. TF-IDF will penalize common words, helping the model find specific key words. The model makes a prediction based on a matrix of word scores and gives a probability of falling into a certain classification. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting ready for training\n",
    "\n",
    "X = model_data[\"selftext_clean\"]\n",
    "y = model_data['is_suicide']\n",
    "# train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "tvec_optimised = TfidfVectorizer(max_df= 0.5, max_features=70, min_df=2, ngram_range=(1, 3),stop_words = 'english')\n",
    "# tvec_optimised = TfidfVectorizer(max_df= 0.5, min_df=2, ngram_range=(1, 3),stop_words = 'english')\n",
    "X_train_tvec = tvec_optimised.fit_transform(X_train).todense()\n",
    "X_test_tvec = tvec_optimised.transform(X_test).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.717948717948718\n",
      "AUC Score: 0.8066258786774277\n"
     ]
    }
   ],
   "source": [
    "# getting accuracies of the model\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train_tvec, y_train)\n",
    "accuracy = nb.score(X_test_tvec, y_test)\n",
    "\n",
    "# calculating AUC\n",
    "\n",
    "pred_proba = [i[1] for i in nb.predict_proba(X_test_tvec)] \n",
    "auc = roc_auc_score(y_test, pred_proba)\n",
    "\n",
    "joblib.dump(nb, \"suicide_vs_nothing.h5\")\n",
    "\n",
    "print(\"Accuracy: {}\\nAUC Score: {}\".format(accuracy, auc) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OnevOneClassifier (mutliclass)\n",
    "ovoc = OneVsOneClassifier(LinearSVC(random_state=0)).fit(X_train_tvec, y_train)# .predict(X_train_tvec)\n",
    "accuracy = ovoc.score(X_test_tvec, y_test)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Performace\n",
    "Our Model performed well, having an accuracy of 70% and an AUC score of 75%. There are most likely ways to improve the classifier, and we will continue to train the model. \n",
    "\n",
    "For our new labeling scheme, we got an accuracy of 76% and an AUC score of 78%.\n",
    "\n",
    "For the clustered labels, we got an accuracy of 75.3% and an AUC score of 81.1%."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
