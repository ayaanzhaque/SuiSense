{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/ayaanzhaque/SuiSense/blob/master/notebooks/BERT/workingBertModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "colab_type": "code",
    "id": "To9ENLU90WGl",
    "outputId": "6cd98743-4f62-4616-8f8e-1cba154e21f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (3.0.2)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
      "Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.91)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied: tokenizers==0.8.1.rc1 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8.1rc1)\n",
      "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
      "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fvFvBLJV0Dkv"
   },
   "outputs": [],
   "source": [
    "#importing relevant libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "import torch\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import transformers as ppb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zQ-42fh0hjsF"
   },
   "source": [
    "## Importing the dataset\n",
    "We'll use pandas to read the dataset and load it into a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cyoj29J24hPX"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/ayaanzhaque/SuiSense/master/data/scheme1.csv')\n",
    "og_batch_1 = df[['selftext', 'New Labels']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dMVE3waNhuNj"
   },
   "source": [
    "For performance reasons, we'll only use 2,000 sentences from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "gTM3hOHW4hUY",
    "outputId": "8530fec4-5b6d-4d05-f90d-ad226149bd91"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>We understand that most people who reply immed...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Welcome to /r/depression's check-in post - a p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I've been feeling really depressed and lonely ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I literally broke down crying and asked to go ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Any kind soul want to give a depressed person ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  1\n",
       "0  We understand that most people who reply immed...  1\n",
       "1  Welcome to /r/depression's check-in post - a p...  1\n",
       "2  I've been feeling really depressed and lonely ...  0\n",
       "3  I literally broke down crying and asked to go ...  0\n",
       "4  Any kind soul want to give a depressed person ...  1"
      ]
     },
     "execution_count": 35,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#batch_1_start = og_batch_1.head(60)\n",
    "#batch_1_end = og_batch_1.tail(60)\n",
    "#test_batch_1 = pd.concat([batch_1_start, batch_1_end], ignore_index=True)\n",
    "batch_1 = og_batch_1.rename(columns={'selftext': 0, 'New Labels': 1})\n",
    "batch_1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PRc2L89hh1Tf"
   },
   "source": [
    "We can ask pandas how many sentences are labeled as \"positive\" (value 1) and how many are labeled \"negative\" (having the value 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "jGvcfcCP5xpZ",
    "outputId": "66fca65a-d4e7-4ce8-81e3-10d4381e0f4e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1446\n",
       "0     451\n",
       "Name: 1, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_1[1].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7_MO08_KiAOb"
   },
   "source": [
    "## Loading the Pre-trained BERT model\n",
    "Let's now load a pre-trained BERT model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q1InADgf5xm2"
   },
   "outputs": [],
   "source": [
    "# For DistilBERT:\n",
    "#model_class, tokenizer_class, pretrained_weights = (ppb.DistilBertModel, ppb.DistilBertTokenizer, 'distilbert-base-uncased')\n",
    "\n",
    "## Want BERT instead of distilBERT? Uncomment the following line:\n",
    "model_class, tokenizer_class, pretrained_weights = (ppb.BertModel, ppb.BertTokenizer, 'bert-base-uncased')\n",
    "\n",
    "# Load pretrained model/tokenizer\n",
    "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "model = model_class.from_pretrained(pretrained_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lZDBMn3wiSX6"
   },
   "source": [
    "Right now, the variable `model` holds a pretrained distilBERT model -- a version of BERT that is smaller, but much faster and requiring a lot less memory.\n",
    "\n",
    "## Model #1: Preparing the Dataset\n",
    "Before we can hand our sentences to BERT, we need to so some minimal processing to put them in the format it requires.\n",
    "\n",
    "### Tokenization\n",
    "Our first step is to tokenize the sentences -- break them up into word and subwords in the format BERT is comfortable with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Dg82ndBA5xlN"
   },
   "outputs": [],
   "source": [
    "tokenized = batch_1[0].apply((lambda x: tokenizer.encode(x, add_special_tokens=True, truncation=True, max_length=128)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "URn-DWJt5xhP"
   },
   "outputs": [],
   "source": [
    "max_len = 0\n",
    "for i in tokenized.values:\n",
    "    if len(i) > max_len:\n",
    "        max_len = len(i)\n",
    "\n",
    "padded = np.array([i + [0]*(max_len-len(i)) for i in tokenized.values])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Mdjg306wjjmL"
   },
   "source": [
    "Our dataset is now in the `padded` variable, we can view its dimensions below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "jdi7uXo95xeq",
    "outputId": "9b203ecf-92ea-4d7d-a12b-dc8566abc7ff"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1897, 128)"
      ]
     },
     "execution_count": 40,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(padded).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sDZBsYSDjzDV"
   },
   "source": [
    "### Masking\n",
    "If we directly send `padded` to BERT, that would slightly confuse it. We need to create another variable to tell it to ignore (mask) the padding we've added when it's processing its input. That's what attention_mask is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "4K_iGRNa_Ozc",
    "outputId": "d0621b87-b32d-43c1-f032-4d8ab28ee209"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1897, 128)"
      ]
     },
     "execution_count": 41,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_mask = np.where(padded != 0, 1, 0)\n",
    "attention_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "39UVjAV56PJz"
   },
   "outputs": [],
   "source": [
    "input_ids = torch.tensor(padded)  \n",
    "attention_mask = torch.tensor(attention_mask)\n",
    "\n",
    "with torch.no_grad():\n",
    "    last_hidden_states = model(input_ids, attention_mask=attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "C9t60At16PVs",
    "outputId": "facff2a3-7612-4d81-84e4-e45e686b1742"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.15627109 -0.20722139 -0.03962984 ...  0.15881492  0.36695075\n",
      "   0.46319005]\n",
      " [-0.05789456 -0.01733888 -0.10708018 ...  0.01880779 -0.06970225\n",
      "   0.54524034]\n",
      " [ 0.19605026  0.20534156  0.24803329 ...  0.15781963  0.45455933\n",
      "  -0.41783777]\n",
      " ...\n",
      " [ 0.04628711  0.53464365 -0.19218408 ... -0.34011787  0.7708874\n",
      "   0.6021303 ]\n",
      " [ 0.24700873  0.2810834   0.21017519 ... -0.1912898   0.2667738\n",
      "  -0.13201511]\n",
      " [ 0.16641247  0.16862674  0.03572434 ... -0.15101409  0.5139446\n",
      "   0.24030764]]\n"
     ]
    }
   ],
   "source": [
    "features = last_hidden_states[0][:,0,:].numpy()\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_VZVU66Gurr-"
   },
   "source": [
    "The labels indicating which sentence is positive and negative now go into the `labels` variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "JD3fX2yh6PTx",
    "outputId": "c9804faf-3afc-4695-8cdd-6fa457a87aee"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    0\n",
       "3    0\n",
       "4    1\n",
       "Name: 1, dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = batch_1[1]\n",
    "labels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iaoEvM2evRx1"
   },
   "source": [
    "## Model #2: Train/Test Split\n",
    "Let's now split our datset into a training set and testing set (even though we're using 2,000 sentences from the SST2 training set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ddAqbkoU6PP9"
   },
   "outputs": [],
   "source": [
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size=0.25, random_state=42, stratify=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cyEwr7yYD3Ci"
   },
   "outputs": [],
   "source": [
    "# parameters = {'C': np.linspace(0.0001, 100, 20)}\n",
    "# grid_search = GridSearchCV(LogisticRegression(), parameters)\n",
    "# grid_search.fit(train_features, train_labels)\n",
    "\n",
    "# print('best parameters: ', grid_search.best_params_)\n",
    "# print('best scrores: ', grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KCT9u8vAwnID"
   },
   "source": [
    "We now train the LogisticRegression model. If you've chosen to do the gridsearch, you can plug the value of C into the model declaration (e.g. `LogisticRegression(C=5.2)`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "gG-EVWx4CzBc",
    "outputId": "ced562e3-8db3-4def-e1fa-ad23d836b42a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 0.6836 - accuracy: 0.6744 - val_loss: 0.6687 - val_accuracy: 0.7621\n",
      "Epoch 2/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.6515 - accuracy: 0.7623 - val_loss: 0.6182 - val_accuracy: 0.7621\n",
      "Epoch 3/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.5874 - accuracy: 0.7623 - val_loss: 0.5676 - val_accuracy: 0.7621\n",
      "Epoch 4/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.5603 - accuracy: 0.7623 - val_loss: 0.5545 - val_accuracy: 0.7621\n",
      "Epoch 5/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.5521 - accuracy: 0.7623 - val_loss: 0.5503 - val_accuracy: 0.7621\n",
      "Epoch 6/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.5495 - accuracy: 0.7623 - val_loss: 0.5491 - val_accuracy: 0.7621\n",
      "Epoch 7/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.5474 - accuracy: 0.7623 - val_loss: 0.5328 - val_accuracy: 0.7621\n",
      "Epoch 8/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.5213 - accuracy: 0.7623 - val_loss: 0.5099 - val_accuracy: 0.7621\n",
      "Epoch 9/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7623 - val_loss: 0.4986 - val_accuracy: 0.7621\n",
      "Epoch 10/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.4937 - accuracy: 0.7623 - val_loss: 0.4923 - val_accuracy: 0.7621\n",
      "Epoch 11/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.4863 - accuracy: 0.7623 - val_loss: 0.4847 - val_accuracy: 0.7621\n",
      "Epoch 12/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.4784 - accuracy: 0.7623 - val_loss: 0.4803 - val_accuracy: 0.7621\n",
      "Epoch 13/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.4726 - accuracy: 0.7623 - val_loss: 0.4802 - val_accuracy: 0.7621\n",
      "Epoch 14/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.4692 - accuracy: 0.7623 - val_loss: 0.4725 - val_accuracy: 0.7621\n",
      "Epoch 15/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.4630 - accuracy: 0.7623 - val_loss: 0.4688 - val_accuracy: 0.7621\n",
      "Epoch 16/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.4586 - accuracy: 0.7623 - val_loss: 0.4651 - val_accuracy: 0.7621\n",
      "Epoch 17/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.4550 - accuracy: 0.7623 - val_loss: 0.4622 - val_accuracy: 0.7621\n",
      "Epoch 18/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.4498 - accuracy: 0.7623 - val_loss: 0.4599 - val_accuracy: 0.7621\n",
      "Epoch 19/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.4462 - accuracy: 0.7623 - val_loss: 0.4572 - val_accuracy: 0.7621\n",
      "Epoch 20/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.4438 - accuracy: 0.7623 - val_loss: 0.4539 - val_accuracy: 0.7621\n",
      "Epoch 21/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.4390 - accuracy: 0.7623 - val_loss: 0.4513 - val_accuracy: 0.7621\n",
      "Epoch 22/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.4350 - accuracy: 0.7623 - val_loss: 0.4524 - val_accuracy: 0.7621\n",
      "Epoch 23/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.4306 - accuracy: 0.7623 - val_loss: 0.4506 - val_accuracy: 0.7621\n",
      "Epoch 24/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.4260 - accuracy: 0.7623 - val_loss: 0.4433 - val_accuracy: 0.7621\n",
      "Epoch 25/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.4213 - accuracy: 0.7623 - val_loss: 0.4417 - val_accuracy: 0.7621\n",
      "Epoch 26/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.4166 - accuracy: 0.7623 - val_loss: 0.4453 - val_accuracy: 0.7621\n",
      "Epoch 27/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.4143 - accuracy: 0.7623 - val_loss: 0.4435 - val_accuracy: 0.7621\n",
      "Epoch 28/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.4095 - accuracy: 0.7623 - val_loss: 0.4416 - val_accuracy: 0.7621\n",
      "Epoch 29/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.4058 - accuracy: 0.7623 - val_loss: 0.4380 - val_accuracy: 0.7621\n",
      "Epoch 30/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.4010 - accuracy: 0.7623 - val_loss: 0.4338 - val_accuracy: 0.7621\n",
      "Epoch 31/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.3970 - accuracy: 0.7623 - val_loss: 0.4466 - val_accuracy: 0.7621\n",
      "Epoch 32/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.3951 - accuracy: 0.7700 - val_loss: 0.4337 - val_accuracy: 0.7895\n",
      "Epoch 33/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.3905 - accuracy: 0.7883 - val_loss: 0.4328 - val_accuracy: 0.7811\n",
      "Epoch 34/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.3882 - accuracy: 0.7897 - val_loss: 0.4323 - val_accuracy: 0.7874\n",
      "Epoch 35/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.3862 - accuracy: 0.7968 - val_loss: 0.4382 - val_accuracy: 0.7811\n",
      "Epoch 36/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.3803 - accuracy: 0.8024 - val_loss: 0.4417 - val_accuracy: 0.7853\n",
      "Epoch 37/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.3774 - accuracy: 0.8087 - val_loss: 0.4370 - val_accuracy: 0.7895\n",
      "Epoch 38/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.3742 - accuracy: 0.8143 - val_loss: 0.4364 - val_accuracy: 0.7832\n",
      "Epoch 39/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.3709 - accuracy: 0.8165 - val_loss: 0.4556 - val_accuracy: 0.7853\n",
      "Epoch 40/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.3752 - accuracy: 0.8158 - val_loss: 0.4485 - val_accuracy: 0.7874\n",
      "Epoch 41/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.3657 - accuracy: 0.8193 - val_loss: 0.4375 - val_accuracy: 0.7768\n",
      "Epoch 42/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.3634 - accuracy: 0.8207 - val_loss: 0.4397 - val_accuracy: 0.7789\n",
      "Epoch 43/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.3596 - accuracy: 0.8207 - val_loss: 0.4472 - val_accuracy: 0.7747\n",
      "Epoch 44/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.3563 - accuracy: 0.8214 - val_loss: 0.4524 - val_accuracy: 0.7747\n",
      "Epoch 45/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.3532 - accuracy: 0.8291 - val_loss: 0.4481 - val_accuracy: 0.7811\n",
      "Epoch 46/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.3495 - accuracy: 0.8298 - val_loss: 0.4476 - val_accuracy: 0.7832\n",
      "Epoch 47/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.3477 - accuracy: 0.8319 - val_loss: 0.4512 - val_accuracy: 0.7832\n",
      "Epoch 48/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.3438 - accuracy: 0.8390 - val_loss: 0.4488 - val_accuracy: 0.7811\n",
      "Epoch 49/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.3406 - accuracy: 0.8425 - val_loss: 0.4478 - val_accuracy: 0.7705\n",
      "Epoch 50/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.3384 - accuracy: 0.8474 - val_loss: 0.4622 - val_accuracy: 0.7789\n",
      "Epoch 51/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.3374 - accuracy: 0.8383 - val_loss: 0.4499 - val_accuracy: 0.7684\n",
      "Epoch 52/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.3324 - accuracy: 0.8495 - val_loss: 0.4550 - val_accuracy: 0.7726\n",
      "Epoch 53/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.3309 - accuracy: 0.8488 - val_loss: 0.4563 - val_accuracy: 0.7705\n",
      "Epoch 54/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.3313 - accuracy: 0.8446 - val_loss: 0.4521 - val_accuracy: 0.7642\n",
      "Epoch 55/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.3245 - accuracy: 0.8530 - val_loss: 0.4640 - val_accuracy: 0.7811\n",
      "Epoch 56/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.3229 - accuracy: 0.8516 - val_loss: 0.4794 - val_accuracy: 0.7853\n",
      "Epoch 57/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.3261 - accuracy: 0.8488 - val_loss: 0.4742 - val_accuracy: 0.7768\n",
      "Epoch 58/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.3189 - accuracy: 0.8537 - val_loss: 0.4914 - val_accuracy: 0.7832\n",
      "Epoch 59/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.3168 - accuracy: 0.8594 - val_loss: 0.4677 - val_accuracy: 0.7684\n",
      "Epoch 60/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.3141 - accuracy: 0.8579 - val_loss: 0.4716 - val_accuracy: 0.7684\n",
      "Epoch 61/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.3101 - accuracy: 0.8671 - val_loss: 0.4767 - val_accuracy: 0.7747\n",
      "Epoch 62/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.3089 - accuracy: 0.8671 - val_loss: 0.4743 - val_accuracy: 0.7663\n",
      "Epoch 63/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.3046 - accuracy: 0.8664 - val_loss: 0.4767 - val_accuracy: 0.7663\n",
      "Epoch 64/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.3023 - accuracy: 0.8678 - val_loss: 0.4794 - val_accuracy: 0.7642\n",
      "Epoch 65/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.3028 - accuracy: 0.8678 - val_loss: 0.4838 - val_accuracy: 0.7726\n",
      "Epoch 66/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.2991 - accuracy: 0.8685 - val_loss: 0.4844 - val_accuracy: 0.7642\n",
      "Epoch 67/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.2981 - accuracy: 0.8650 - val_loss: 0.5074 - val_accuracy: 0.7811\n",
      "Epoch 68/100\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.2943 - accuracy: 0.8706 - val_loss: 0.4882 - val_accuracy: 0.7684\n",
      "Epoch 69/100\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.2935 - accuracy: 0.8741 - val_loss: 0.5003 - val_accuracy: 0.7684\n",
      "Epoch 70/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.2899 - accuracy: 0.8762 - val_loss: 0.4871 - val_accuracy: 0.7663\n",
      "Epoch 71/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.2908 - accuracy: 0.8713 - val_loss: 0.5197 - val_accuracy: 0.7789\n",
      "Epoch 72/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.2917 - accuracy: 0.8713 - val_loss: 0.5070 - val_accuracy: 0.7684\n",
      "Epoch 73/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.2840 - accuracy: 0.8720 - val_loss: 0.4972 - val_accuracy: 0.7768\n",
      "Epoch 74/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.2805 - accuracy: 0.8826 - val_loss: 0.5089 - val_accuracy: 0.7705\n",
      "Epoch 75/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.2827 - accuracy: 0.8783 - val_loss: 0.5100 - val_accuracy: 0.7705\n",
      "Epoch 76/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.2752 - accuracy: 0.8797 - val_loss: 0.5275 - val_accuracy: 0.7705\n",
      "Epoch 77/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.2798 - accuracy: 0.8868 - val_loss: 0.5322 - val_accuracy: 0.7747\n",
      "Epoch 78/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.2746 - accuracy: 0.8875 - val_loss: 0.5011 - val_accuracy: 0.7516\n",
      "Epoch 79/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.2817 - accuracy: 0.8755 - val_loss: 0.5057 - val_accuracy: 0.7537\n",
      "Epoch 80/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.2709 - accuracy: 0.8882 - val_loss: 0.5285 - val_accuracy: 0.7747\n",
      "Epoch 81/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.2686 - accuracy: 0.8868 - val_loss: 0.5148 - val_accuracy: 0.7537\n",
      "Epoch 82/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.2685 - accuracy: 0.8882 - val_loss: 0.5263 - val_accuracy: 0.7705\n",
      "Epoch 83/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.2637 - accuracy: 0.8910 - val_loss: 0.5250 - val_accuracy: 0.7705\n",
      "Epoch 84/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.2620 - accuracy: 0.8931 - val_loss: 0.5216 - val_accuracy: 0.7579\n",
      "Epoch 85/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.2629 - accuracy: 0.8917 - val_loss: 0.5245 - val_accuracy: 0.7600\n",
      "Epoch 86/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.2602 - accuracy: 0.8980 - val_loss: 0.5279 - val_accuracy: 0.7537\n",
      "Epoch 87/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.2550 - accuracy: 0.8917 - val_loss: 0.5576 - val_accuracy: 0.7747\n",
      "Epoch 88/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.2648 - accuracy: 0.8959 - val_loss: 0.5457 - val_accuracy: 0.7726\n",
      "Epoch 89/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.2546 - accuracy: 0.8987 - val_loss: 0.5575 - val_accuracy: 0.7768\n",
      "Epoch 90/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.2564 - accuracy: 0.8952 - val_loss: 0.5378 - val_accuracy: 0.7600\n",
      "Epoch 91/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.2515 - accuracy: 0.9001 - val_loss: 0.5451 - val_accuracy: 0.7579\n",
      "Epoch 92/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.2530 - accuracy: 0.8952 - val_loss: 0.5730 - val_accuracy: 0.7747\n",
      "Epoch 93/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.2491 - accuracy: 0.8966 - val_loss: 0.5407 - val_accuracy: 0.7537\n",
      "Epoch 94/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.2514 - accuracy: 0.8945 - val_loss: 0.5603 - val_accuracy: 0.7663\n",
      "Epoch 95/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.2454 - accuracy: 0.8973 - val_loss: 0.5753 - val_accuracy: 0.7747\n",
      "Epoch 96/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.2505 - accuracy: 0.8966 - val_loss: 0.5716 - val_accuracy: 0.7684\n",
      "Epoch 97/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.2623 - accuracy: 0.8882 - val_loss: 0.5787 - val_accuracy: 0.7789\n",
      "Epoch 98/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.2427 - accuracy: 0.9037 - val_loss: 0.5730 - val_accuracy: 0.7747\n",
      "Epoch 99/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.2392 - accuracy: 0.9079 - val_loss: 0.5734 - val_accuracy: 0.7663\n",
      "Epoch 100/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.2382 - accuracy: 0.9072 - val_loss: 0.5598 - val_accuracy: 0.7537\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.layers import Dense, Activation, Embedding, Flatten, GlobalMaxPool1D, Dropout, Conv1D\n",
    "\n",
    "model3 = Sequential()\n",
    "model3.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model3.add(Dense(10, activation='relu'))\n",
    "model3.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model3.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model3.fit(train_features, train_labels, batch_size=32, epochs=100, verbose=1, validation_data=(test_features, test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3rUMKuVgwzkY"
   },
   "source": [
    "<img src=\"https://jalammar.github.io/images/distilBERT/bert-training-logistic-regression.png\" />\n",
    "\n",
    "## Evaluating Model #2\n",
    "So how well does our model do in classifying sentences? One way is to check the accuracy against the testing dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "iCoyxRJ7ECTA",
    "outputId": "e99bb70e-59d6-4e58-b7fc-a2e84c977d71"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6905263157894737"
      ]
     },
     "execution_count": 64,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_clf.score(test_features, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "75oyhr3VxHoE"
   },
   "source": [
    "How good is this score? What can we compare it against? Let's first look at a dummy classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "lnwgmqNG7i5l",
    "outputId": "c50a0610-b531-4435-bd0e-f57d75ac11c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy classifier score: 0.636 (+/- 0.06)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "clf = DummyClassifier()\n",
    "\n",
    "scores = cross_val_score(clf, train_features, train_labels)\n",
    "print(\"Dummy classifier score: %0.3f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7Lg4LOpoxSOR"
   },
   "source": [
    "So our model clearly does better than a dummy classifier. But how does it compare against the best models?\n",
    "\n",
    "## Proper SST2 scores\n",
    "For reference, the [highest accuracy score](http://nlpprogress.com/english/sentiment_analysis.html) for this dataset is currently **96.8**. DistilBERT can be trained to improve its score on this task – a process called **fine-tuning** which updates BERT’s weights to make it achieve a better performance in this sentence classification task (which we can call the downstream task). The fine-tuned DistilBERT turns out to achieve an accuracy score of **90.7**. The full size BERT model achieves **94.9**.\n",
    "\n",
    "\n",
    "\n",
    "And that’s it! That’s a good first contact with BERT. The next step would be to head over to the documentation and try your hand at [fine-tuning](https://huggingface.co/transformers/examples.html#glue). You can also go back and switch from distilBERT to BERT and see how that works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EJQuqV6cnWQu"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "include_colab_link": true,
   "name": "workingBertModel.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
